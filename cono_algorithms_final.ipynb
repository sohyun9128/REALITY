{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i6NZONmpztqs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import natsort \n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "# 전환된 이미지파일 저장할 경로\n",
    "imgs_path = './img'  \n",
    "\n",
    "\n",
    "# 테스트 비디오 경로\n",
    "test_video_path = './test.mp4'  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "toImages(): \n",
    "    동영상을 이미지로 변환해주는 함수.\n",
    "\n",
    "Args:\n",
    "    - img_path: 변환할 이미지를 저장할 경로.\n",
    "    - input_video_file: 이미지로 변환할 비디오 경로.\n",
    "\n",
    "Returns:\n",
    "    \n",
    "\"\"\"\n",
    "def toImages(img_path, input_video_file):\n",
    "\n",
    "    cam = cv2.VideoCapture(input_video_file)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        flag, frame = cam.read()\n",
    "        if flag:\n",
    "            cv2.imwrite(os.path.join(img_path, str(counter) + '.jpg'),frame)\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            break\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "runDetector(): \n",
    "    이미지에서 객체를 탐지하는 함수(Faster-RCNN 적용).\n",
    "\n",
    "Args:\n",
    "    - detector: 객체 탐지 모듈\n",
    "    - path: 모듈을 적용시킬 이미지 파일의 경로\n",
    "\n",
    "Returns:\n",
    "    - df: 프레임별 탐지된 객체들의 위치 정보가 담긴 DataFrame\n",
    "    \n",
    "\"\"\"\n",
    "def runDetector(detector, path):\n",
    "    \n",
    "  df = pd.DataFrame(columns=['id', 'x', 'y'])\n",
    "    \n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  result = detector(converted_img)\n",
    "\n",
    "  result = {key:value.numpy() for key,value in result.items()}\n",
    "    \n",
    "  max_boxes = 10\n",
    "  min_score = 0.1\n",
    "\n",
    "  boxes = result[\"detection_boxes\"]\n",
    "  class_names = result[\"detection_class_entities\"]\n",
    "  scores = result[\"detection_scores\"]\n",
    "\n",
    "    \n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    \n",
    "    if scores[i] >= min_score:\n",
    "        \n",
    "      image = Image.fromarray(np.uint8(img.numpy())).convert(\"RGB\")\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      im_width, im_height = image.size\n",
    "      (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                    ymin * im_height, ymax * im_height)\n",
    "    \n",
    "      display_str = [class_names[i].decode(\"ascii\"), int(100 * scores[i])]\n",
    "  \n",
    "      if display_str[0] == 'Person':\n",
    "        df = df.append({'id' : display_str[0], 'x' : float(left+right)/2.0, 'y' : float(top+bottom)/2.0}, ignore_index=True)\n",
    "  return df\n",
    "\n",
    "\n",
    "\n",
    "def distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "objectIndexing(): \n",
    "    같은 Class에 속하는 객체들을 구분하여 id값을 지정해주는 함수\n",
    "\n",
    "Args:\n",
    "    - output_df: run_detector()의 return 값으로 전달된 DataFrame\n",
    "\n",
    "Returns:\n",
    "    - 객체들의 id 값이 담긴 list\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def objectIndexing(output_df):\n",
    "    count_num = 0\n",
    "\n",
    "    for i in range(len(output_df.index)):\n",
    "        if output_df[0][i] == 'frame':\n",
    "          exec(\"frame%d = pd.DataFrame(columns=['id', 'x', 'y'])\" % count_num)\n",
    "          count_num += 1\n",
    "        elif count_num <= 1:\n",
    "          exec(\"frame%d = frame%d.append({'id' : %d, 'x' : output_df[1][%d], 'y' : output_df[2][%d]}, ignore_index=True)\" % (count_num-1, count_num-1, i, i, i))\n",
    "        else:\n",
    "          exec(\"frame%d = frame%d.append({'id' : 0, 'x' : output_df[1][%d], 'y' : output_df[2][%d]}, ignore_index=True)\" % (count_num-1, count_num-1, i, i))\n",
    "        \n",
    "        \n",
    "    max_id = 0\n",
    "    id = 0\n",
    "    for i in range(count_num):\n",
    "      exec(\"id = len(frame%d['id'].index)\" % i)\n",
    "      if max_id < id:\n",
    "          max_id = id\n",
    "\n",
    "        \n",
    "    return_id_list = ['frame']\n",
    "    exec(\"return_id_list += list(frame%d['id'])\" % 0)\n",
    "\n",
    "    \n",
    "    # 프레임 수 -1번 반복\n",
    "    for frameNum in range(count_num-1):\n",
    "        exec(\"beforeF = frame%d\" % int(frameNum))\n",
    "        exec(\"afterF = frame%d\" % int(frameNum+1))\n",
    "        globals().update(locals())\n",
    "        \n",
    "\n",
    "        # 객체의 수 변화X\n",
    "        if len(beforeF.index) == len(afterF.index):\n",
    "          afteridx = list(range(len(afterF.index)))\n",
    "          for beforeIdx in range(len(beforeF.index)):\n",
    "              x = beforeF['x'][beforeIdx]\n",
    "              y = beforeF['y'][beforeIdx]\n",
    "              minidx = -1\n",
    "              mindis = 999\n",
    "              for afterCount in afteridx:\n",
    "                dis = distance(x, y, afterF['x'][afterCount], afterF['y'][afterCount])\n",
    "                if mindis > dis:\n",
    "                  minidx = afterCount\n",
    "                  mindis = dis\n",
    "              afterF['id'][minidx] = beforeF['id'][beforeIdx]\n",
    "              afteridx.remove(minidx)\n",
    "\n",
    "        # 객체의 수 감소\n",
    "        elif len(beforeF.index) > len(afterF.index):\n",
    "            beforeidx = list(range(len(beforeF.index)))\n",
    "            for afterIdx in range(len(afterF.index)):\n",
    "                x = afterF['x'][afterIdx]\n",
    "                y = afterF['y'][afterIdx]\n",
    "                minidx = -1\n",
    "                mindis = 999\n",
    "                for beforeCount in beforeidx:\n",
    "                  dis = distance(x, y, beforeF['x'][beforeCount], beforeF['y'][beforeCount])\n",
    "                  if mindis > dis:\n",
    "                    minidx = beforeCount\n",
    "                    mindis = dis\n",
    "                    \n",
    "                afterF['id'][afterIdx] = beforeF['id'][minidx]\n",
    "                beforeidx.remove(minidx)      \n",
    "            \n",
    "\n",
    "        # 객체의 수 증가    \n",
    "        else:\n",
    "            afteridx = list(range(len(afterF.index)))\n",
    "            for beforeIdx in range(len(beforeF.index)):\n",
    "                x = beforeF['x'][beforeIdx]\n",
    "                y = beforeF['y'][beforeIdx]\n",
    "                minidx = -1\n",
    "                mindis = 999\n",
    "                for afterCount in afteridx:\n",
    "                  dis = distance(x, y, afterF['x'][afterCount], afterF['y'][afterCount])\n",
    "                  if mindis > dis:\n",
    "                    minidx = afterCount\n",
    "                    mindis = dis\n",
    "                afterF['id'][minidx] = beforeF['id'][beforeIdx]\n",
    "                afteridx.remove(minidx) \n",
    "\n",
    "            for i in range(len(afterF.index)):\n",
    "              if afterF['id'][i] == 0.0:\n",
    "                afterF['id'][i] = max_id\n",
    "                max_id += 1\n",
    "\n",
    "        return_id_list += ['frame']\n",
    "        exec(\"return_id_list += list(afterF['id'])\")\n",
    "\n",
    "    return return_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3MXlBWCztqz",
    "outputId": "3422d99d-82e2-48c5-89ee-8930c9391459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time :  20.983333333333334\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# conver to imgs\n",
    "toImages(imgs_path, test_video_path)\n",
    "\n",
    "\n",
    "# module load\n",
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "detector = hub.load(module_handle).signatures['default']\n",
    "\n",
    "# imgs load\n",
    "imgs= glob.glob(imgs_path+'/*.jpg')\n",
    "imgs =  natsort.natsorted(imgs)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['id', 'x', 'y'])\n",
    "frame_count = 0\n",
    "\n",
    "# run detector\n",
    "for file in imgs:\n",
    "    frame_df = runDetector(detector, file)\n",
    "    final_df = final_df.append({'id' : 'frame', 'x' : frame_count, 'y' : len(frame_df.index)}, ignore_index = True)\n",
    "    final_df = final_df.append(frame_df, ignore_index=True)\n",
    "    frame_count += 1\n",
    "\n",
    "# save df to txt\n",
    "final_df.to_csv('output.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "# load txt to df\n",
    "output_df = pd.read_csv('output.txt', sep='\\t', header=None)\n",
    "\n",
    "# 객체 구분 알고리즘\n",
    "id_list = objectIndexing(output_df)\n",
    "\n",
    "output_df[0] = id_list\n",
    "output_df.to_csv('reality_data.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('time : ', int(end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bXpkI0FVAYz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cono_algorithms_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
